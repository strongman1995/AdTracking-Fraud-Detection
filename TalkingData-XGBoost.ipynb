{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TalkingData-XGBoost\n",
    "\n",
    "created by chenlu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already show u some analysis of raw data in the previous notebook, *EDA.ipynb*.\n",
    "\n",
    "This notebook constructs a complete pipeline from preprocessing raw data to output final submission\n",
    "\n",
    "## [Phase 1 : Feature Engineering](#phase1)\n",
    "1. Sampling data\n",
    "2. Preprocessing sampled data\n",
    "3. Generating features, save feature matrix\n",
    "4. Evaluate feature importance within feature groups\n",
    "5. Select important features\n",
    "6. Seperate train/dev/test set\n",
    "\n",
    "## [Phase 2 : Training Model](#phase2)\n",
    "1. Preprocessing full data\n",
    "2. Generating features selected from last phrase\n",
    "3. Seperate train/dev/test set\n",
    "4. Negative down-sampling (posive : negative = 1 : 1)(3 down-sampled datasets)\n",
    "5. Experiments on the effect of down-sampling\n",
    "6. Training 3 XGBoost models on 3 sampled datasets\n",
    "7. Tuning the model\n",
    "\n",
    "## [Phase 3 : Predict & Output](#phase3)\n",
    "1. Predict test set using 3 well-train models\n",
    "2. Generate 3 submission files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "\n",
    "    train.csv -> 184,903,891 rows\n",
    "    \n",
    "    test.csv -> 18,790,470 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='phase1'></a>\n",
    "## Phase1 : Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sampling_data'>1.Sampling data</a>\n",
    "\n",
    "Because of big unbalanced raw data, first we reserved full positive cases and sampled 10% percent of negative cases from train data based on the proportion of Day 7 & 8 & 9. \n",
    "\n",
    "And take Day 7&8 as train set, Day 9 as dev set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import gc\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from generate_features import *\n",
    "from model import *\n",
    "\n",
    "path = '../input/'\n",
    "\n",
    "train_columns = ['ip', 'app', 'device', 'os', 'channel', 'click_time', 'is_attributed']\n",
    "test_columns  = ['ip', 'app', 'device', 'os', 'channel', 'click_time', 'click_id']\n",
    "dtypes = {\n",
    "        'ip'            : 'uint32',\n",
    "        'app'           : 'uint16',\n",
    "        'device'        : 'uint16',\n",
    "        'os'            : 'uint16',\n",
    "        'channel'       : 'uint16',\n",
    "        'is_attributed' : 'uint8',\n",
    "        'click_id'      : 'uint32',\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "# Read the last lines because they are more impacting in training than the starting lines\n",
    "train = pd.read_csv(f\"{path}train.csv\", usecols=train_columns, dtype=dtypes, parse_dates=['click_time'])\n",
    "test = pd.read_csv(f\"{path}test.csv\", usecols=test_columns, dtype=dtypes, parse_dates=['click_time'])\n",
    "print(f'[{time.time() - start_time}] Finished to load data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = time_features(train)\n",
    "gc.collect()\n",
    "test = time_features(test)\n",
    "gc.collect()\n",
    "\n",
    "frac = 0.05\n",
    "train_7 = pd.concat([train[(train['is_attributed']==0) & (train['day']==7)].sample(frac=frac),\\\n",
    "                     train[(train['is_attributed']==1) & (train['day']==7)]]).reset_index(drop=True)\n",
    "train_8 = pd.concat([train[(train['is_attributed']==0) & (train['day']==8)].sample(frac=frac),\\\n",
    "                     train[(train['is_attributed']==1) & (train['day']==8)]]).reset_index(drop=True)\n",
    "train_9 = pd.concat([train[(train['is_attributed']==0) & (train['day']==9)].sample(frac=frac),\\\n",
    "                     train[(train['is_attributed']==1) & (train['day']==9)]]).reset_index(drop=True)\n",
    "\n",
    "X_train = pd.concat([train_7,train_8])\n",
    "del train, train_7,train_8\n",
    "gc.collect()\n",
    "\n",
    "# sampled train data\n",
    "train = pd.concat([X_train,train_9])\n",
    "del X_train, train_9\n",
    "gc.collect()\n",
    "\n",
    "# X_total = train + test\n",
    "test['is_attributed'] = np.nan\n",
    "X_total = pd.concat([train,test.drop(['click_id'], axis=1)])\n",
    "del train, test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_total.to_pickle('intermediate/X_total.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_total.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='generating_features'>\n",
    "3.Generating features\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you already run the previous cells, you can start here.\n",
    "\n",
    "Training XGBoost Model\n",
    "\n",
    "Save feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X_total = pd.read_pickle('X_total.pkl.gz')\n",
    "X_total = pd.read_pickle('intermediate/X_total.pkl.gz')\n",
    "plot_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_total_ = X_total\n",
    "clf, evals_result = xgb_train(X_total_)\n",
    "plot_df['base'] = evals_result['validation_0']['auc']\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_name = \"base\"\n",
    "modelname = f\"intermediate/{feature_name}_clf.pkl.gz\"\n",
    "feat_mat = f\"intermediate/{feature_name}.pkl.gz\"\n",
    "pickle.dump(clf, open(modelname, 'wb'))\n",
    "X_total_.to_pickle(feat_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clicks by ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_total_ = clicks_by_ip(X_total)\n",
    "clf, evals_result = xgb_train(X_total_)\n",
    "plot_df['clicks_by_ip'] = evals_result['validation_0']['auc']\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_name = \"clicks_by_ip\"\n",
    "modelname = f\"intermediate/{feature_name}_clf.pkl.gz\"\n",
    "feat_mat = f\"intermediate/{feature_name}.pkl.gz\"\n",
    "pickle.dump(clf, open(modelname, 'wb'))\n",
    "X_total_.to_pickle(feat_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "confidence rate feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X_total[X_total['day'] != 10]\n",
    "X_total_ = confidence_rate_feature(X_total, X_train)\n",
    "clf, evals_result = xgb_train(X_total_)\n",
    "plot_df['confidence_rate_feature'] = evals_result['validation_0']['auc']\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_name = \"confidence_rate_feature\"\n",
    "modelname = f\"intermediate/{feature_name}_clf.pkl.gz\"\n",
    "feat_mat = f\"intermediate/{feature_name}.pkl.gz\"\n",
    "pickle.dump(clf, open(modelname, 'wb'))\n",
    "X_total_.to_pickle(feat_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "group by feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_total_ = group_by_feature(X_total)\n",
    "clf, evals_result = xgb_train(X_total_)\n",
    "plot_df['group_by_feature'] = evals_result['validation_0']['auc']\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_name = \"group_by_feature\"\n",
    "modelname = f\"intermediate/{feature_name}_clf.pkl.gz\"\n",
    "feat_mat = f\"intermediate/{feature_name}.pkl.gz\"\n",
    "pickle.dump(clf, open(modelname, 'wb'))\n",
    "X_total_.to_pickle(feat_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next click feature (very slow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_total_ = next_click_feature(X_total)\n",
    "clf, evals_result = xgb_train(X_total_)\n",
    "plot_df['next_click_feature'] = evals_result['validation_0']['auc']\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_name = \"next_click_feature\"\n",
    "modelname = f\"intermediate/{feature_name}_clf.pkl.gz\"\n",
    "feat_mat = f\"intermediate/{feature_name}.pkl.gz\"\n",
    "pickle.dump(clf, open(modelname, 'wb'))\n",
    "X_total_.to_pickle(feat_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "history click feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_total_ = history_click_feature(X_total)\n",
    "clf, evals_result = xgb_train(X_total_)\n",
    "plot_df['history_click_feature'] = evals_result['validation_0']['auc']\n",
    "gc.collect() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_name = \"history_click_feature\"\n",
    "modelname = f\"intermediate/{feature_name}_clf.pkl.gz\"\n",
    "feat_mat = f\"intermediate/{feature_name}.pkl.gz\"\n",
    "pickle.dump(clf, open(modelname, 'wb'))\n",
    "X_total_.to_pickle(feat_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "topic feature (very slow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# X_total_ = topic_feature(X_total)\n",
    "clf, evals_result = easy_train(X_total)\n",
    "plot_df['topic_feature'] = evals_result['validation_0']['auc']\n",
    "gc.collect()\n",
    "\n",
    "feature_name = \"topic_feature\"\n",
    "modelname = f\"model/{feature_name}_clf.pkl.gz\"\n",
    "feat_mat = f\"feature/{feature_name}.pkl.gz\"\n",
    "pickle.dump(clf, open(modelname, 'wb'))\n",
    "# X_total_.to_pickle(feat_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_name = \"topic_feature\"\n",
    "modelname = f\"model/{feature_name}_clf.pkl.gz\"\n",
    "feat_mat = f\"feature/{feature_name}.pkl.gz\"\n",
    "pickle.dump(clf, open(modelname, 'wb'))\n",
    "# X_total_.to_pickle(feat_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot the improvement of model because of features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_name = 'topic_feature'\n",
    "modelname = f\"intermediate/{feature_name}_clf.pkl.gz\"\n",
    "clf = pickle.load(open(modelname, 'rb'))\n",
    "plot_df[feature_name] = clf.evals_result()['validation_0']['auc']\n",
    "# plot_df.to_pickle('plot_df.pkl.gz')\n",
    "# plot_df = pd.read_pickle('plot_df.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = ['base', 'base+clicks_by_ip', 'base+conf_rate', \n",
    "          'base+group_by',  'base+next_click', \n",
    "          'base+history_click', 'base_topic']\n",
    "plt.boxplot(plot_df.T, showfliers=False, labels=labels, vert=True)\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=20)\n",
    "plt.ylabel('AUC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate feature importance within feature groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def eval_within_groups(feature_name):\n",
    "    feat_mat = f\"feature/{feature_name}.pkl.gz\"\n",
    "    modelname = f\"model/{feature_name}_clf.pkl.gz\"\n",
    "    clf = pickle.load(open(modelname, 'rb'))\n",
    "    X_total = pd.read_pickle(feat_mat)\n",
    "    X_total = X_total[X_total['day']!=10]\n",
    "\n",
    "    # Get xgBoost importances\n",
    "    importance_dict = {}\n",
    "    for import_type in ['weight']:\n",
    "        importance_dict['xgBoost-'+import_type] = clf.get_booster().get_fscore()\n",
    "\n",
    "    # MinMax scale all importances\n",
    "    importance_df = pd.DataFrame(importance_dict).fillna(0)\n",
    "    importance_df = pd.DataFrame(\n",
    "        preprocessing.MinMaxScaler().fit_transform(importance_df),\n",
    "        columns=importance_df.columns,\n",
    "        index=importance_df.index\n",
    "    )\n",
    "\n",
    "    sum_features = sum(importance_df['xgBoost-weight'])\n",
    "    importance_df = importance_df.sort_values('xgBoost-weight',ascending=False)\n",
    "    weight_list = importance_df['xgBoost-weight']\n",
    "    col_70, col_80, col_90 = [], [], []\n",
    "\n",
    "    cur_sum = 0\n",
    "    for i, col in enumerate(importance_df.index):\n",
    "        cur_sum += weight_list[i]\n",
    "        if 1.0*cur_sum/sum_features < 0.7:\n",
    "            col_70.append(col)\n",
    "        if 1.0*cur_sum/sum_features < 0.8:\n",
    "            col_80.append(col)\n",
    "        if 1.0*cur_sum/sum_features < 0.9:   \n",
    "            col_90.append(col)\n",
    "\n",
    "    if 'day' not in col_70:\n",
    "        col_70.append('day')\n",
    "    if 'day' not in col_80:\n",
    "        col_80.append('day')\n",
    "    if 'day' not in col_90:\n",
    "        col_90.append('day')    \n",
    "    if 'is_attributed' not in col_70:\n",
    "        col_70.append('is_attributed')\n",
    "    if 'is_attributed' not in col_80:\n",
    "        col_80.append('is_attributed')\n",
    "    if 'is_attributed' not in col_90:\n",
    "        col_90.append('is_attributed')     \n",
    "\n",
    "    print(len(col_70), len(col_80), len(col_90), len(importance_df.index))\n",
    "\n",
    "    plot_df = pd.DataFrame()\n",
    "    \n",
    "    clf = pickle.load(open(f'model/{feature_name}_70_clf.pkl.gz', 'rb'))\n",
    "    plot_df['70'] = clf.evals_result()['validation_0']['auc']\n",
    "    gc.collect()\n",
    "    print(\"70 done\")\n",
    "    clf, evals_result = xgb_train(X_total[col_80])\n",
    "    pickle.dump(clf, open(f'model/{feature_name}_80_clf.pkl.gz', 'wb'))\n",
    "    plot_df['80'] = evals_result['validation_0']['auc']\n",
    "    gc.collect()\n",
    "    print(\"80 done\")\n",
    "    clf, evals_result = xgb_train(X_total[col_90])\n",
    "    pickle.dump(clf, open(f'model/{feature_name}_90_clf.pkl.gz', 'wb'))\n",
    "    plot_df['90'] = evals_result['validation_0']['auc']\n",
    "    gc.collect()\n",
    "    print(\"90 done\")\n",
    "    clf = pickle.load(open(modelname, 'rb'))\n",
    "    plot_df['100'] = clf.evals_result()['validation_0']['auc']\n",
    "    gc.collect()\n",
    "    \n",
    "    labels = ['70%', '80%', '90%', '100%']\n",
    "    plt.boxplot(plot_df.T, showfliers=False, labels=labels, vert=True)\n",
    "    plt.grid(True)\n",
    "    plt.xticks(rotation=20)\n",
    "    plt.ylabel('AUC')\n",
    "    plt.title(f'evaluation within {feature_name} groups')\n",
    "    plt.savefig(f'evaluation_within_{feature_name}_groups.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "confidence_rate_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_within_groups('confidence_rate_feature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "group_by_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_within_groups('group_by_feature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next_click_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_within_groups('next_click_feature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "history_click_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_within_groups('history_click_feature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "topic_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_within_groups('topic_feature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate feature importance\n",
    "\n",
    "The feature importances are MinMax scaled, put into a DataFrame, and finally plotted ordered by the mean feature importance.\n",
    "\n",
    "xgboost-weight = importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_important_features(feature_name, figzise):\n",
    "    modelname = f\"intermediate/{feature_name}_clf.pkl.gz\"\n",
    "    clf = pickle.load(open(modelname, 'rb'))\n",
    "\n",
    "    fig, ax = plt.subplots(1,1,figsize=figzise)\n",
    "    plot_importance(clf, ax=ax)\n",
    "    plt.show()\n",
    "\n",
    "    plot_feature_importance(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_important_features('base',[8, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clicks_by_ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_important_features('clicks_by_ip',[8,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "confidence_rate_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_important_features('confidence_rate_feature',[8,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "group_by_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_important_features('group_by_feature',[8,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next_click_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_important_features('next_click_feature',[8,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "history_click_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_important_features('history_click_feature',[8,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "topic_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_important_features('topic_feature',[13,50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='phase2'></a>\n",
    "## Phase 2 : Training Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Preprocessing full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the last lines because they are more impacting in training than the starting lines\n",
    "train = pd.read_csv(path+\"train.csv\", usecols=train_columns, dtype=dtypes, parse_dates=['click_time'])\n",
    "test = pd.read_csv(path+\"test.csv\", usecols=test_columns, dtype=dtypes, parse_dates=['click_time'])\n",
    "print('[{}] Finished to load data'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = time_features(train)\n",
    "gc.collect()\n",
    "test = time_features(test)\n",
    "gc.collect()\n",
    "\n",
    "test['is_attributed'] = np.nan\n",
    "X_total = pd.concat([train,test.drop(['click_id'], axis=1)])\n",
    "# combine clicks by ip into X_total\n",
    "X_total_ = clicks_by_ip(X_total)\n",
    "del train, test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_name = \"confidence_rate_feature\"\n",
    "X_total_ = confidence_rate_feature(X_total)\n",
    "feat_mat = f\"feature/{feature_name}.pkl.gz\"\n",
    "X_total_.to_pickle(feat_mat)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_name = \"group_by_feature\"\n",
    "X_total_ = group_by_feature(X_total)\n",
    "feat_mat = f\"feature/{feature_name}.pkl.gz\"\n",
    "X_total_.to_pickle(feat_mat)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_name = \"next_click_feature\"\n",
    "X_total_ = next_click_feature(X_total)\n",
    "feat_mat = f\"feature/{feature_name}.pkl.gz\"\n",
    "X_total_.to_pickle(feat_mat)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_name = \"history_click_feature\"\n",
    "X_total_ = history_click_feature(X_total)\n",
    "feat_mat = f\"feature/{feature_name}.pkl.gz\"\n",
    "X_total_.to_pickle(feat_mat)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_name = \"topic_feature\"\n",
    "X_total_ = topic_feature(X_total)\n",
    "feat_mat = f\"feature/{feature_name}.pkl.gz\"\n",
    "X_total_.to_pickle(feat_mat)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Generating features selected from last phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# features\n",
    "basic = ['ip','hour','minute']\n",
    "\n",
    "conf_rate_v1 = ['app_confRate','channel_confRate','ip_confRate']\n",
    "conf_rate_v2 = ['app_channel_confRate','app_os_confRate','app_device_confRate']\n",
    "conf_rate_v3 = ['channel_device_confRate','channel_os_confRate','os_device_confRate']\n",
    "\n",
    "group_by_v1 = ['ip_day_hour_count_channel']\n",
    "group_by_v2 = ['app_count_channel','channel_count_app']\n",
    "group_by_v3 = ['ip_cumcount_app','ip_nunique_device','ip_device_os_cumcount_app','ip_nunique_app','ip_nunique_channel']\n",
    "\n",
    "next_click_v1 = ['ip_nextClick','ip_app_nextClick','ip_os_nextClick','ip_channel_nextClick']\n",
    "next_click_v3 = ['ip_os_device_app_nextClick','ip_app_device_os_channel_nextClick']\n",
    "\n",
    "history_click = ['future_app_clicks','future_identical_clicks']\n",
    "\n",
    "# choose\n",
    "chosen_features = basic+conf_rate_v1+conf_rate_v2+conf_rate_v3 \\\n",
    "                    +group_by_v1+group_by_v2+group_by_v3 \\\n",
    "                    +next_click_v1+next_click_v3 \\\n",
    "                    +history_click"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### experiments on features importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_within_groups(feature_name):\n",
    "    feat_mat = f\"feature/{feature_name}.pkl.gz\"\n",
    "    modelname = f\"model/{feature_name}_clf.pkl.gz\"\n",
    "    clf = pickle.load(open(modelname, 'rb'))\n",
    "    X_total = pd.read_pickle(feat_mat)\n",
    "    X_total = X_total[X_total['day']!=10]\n",
    "\n",
    "    # Get xgBoost importances\n",
    "    importance_dict = {}\n",
    "    for import_type in ['weight']:\n",
    "        importance_dict['xgBoost-'+import_type] = clf.get_booster().get_fscore()\n",
    "\n",
    "    # MinMax scale all importances\n",
    "    importance_df = pd.DataFrame(importance_dict).fillna(0)\n",
    "    importance_df = pd.DataFrame(\n",
    "        preprocessing.MinMaxScaler().fit_transform(importance_df),\n",
    "        columns=importance_df.columns,\n",
    "        index=importance_df.index\n",
    "    )\n",
    "\n",
    "    sum_features = sum(importance_df['xgBoost-weight'])\n",
    "    importance_df = importance_df.sort_values('xgBoost-weight',ascending=False)\n",
    "    weight_list = importance_df['xgBoost-weight']\n",
    "    col_70, col_80, col_90 = [], [], []\n",
    "\n",
    "    cur_sum = 0\n",
    "    for i, col in enumerate(importance_df.index):\n",
    "        cur_sum += weight_list[i]\n",
    "        if 1.0*cur_sum/sum_features < 0.7:\n",
    "            col_70.append(col)\n",
    "        if 1.0*cur_sum/sum_features < 0.8:\n",
    "            col_80.append(col)\n",
    "        if 1.0*cur_sum/sum_features < 0.9:   \n",
    "            col_90.append(col)\n",
    "\n",
    "    if 'day' not in col_70:\n",
    "        col_70.append('day')\n",
    "    if 'day' not in col_80:\n",
    "        col_80.append('day')\n",
    "    if 'day' not in col_90:\n",
    "        col_90.append('day')    \n",
    "    if 'is_attributed' not in col_70:\n",
    "        col_70.append('is_attributed')\n",
    "    if 'is_attributed' not in col_80:\n",
    "        col_80.append('is_attributed')\n",
    "    if 'is_attributed' not in col_90:\n",
    "        col_90.append('is_attributed')     \n",
    "\n",
    "    print(len(col_70), len(col_80), len(col_90), len(importance_df.index))\n",
    "\n",
    "    plot_df = pd.DataFrame()\n",
    "    clf, evals_result = xgb_train(X_total[col_70])\n",
    "    pickle.dump(clf, open(f'model/{feature_name}_70_clf.pkl.gz', 'wb'))\n",
    "    plot_df['70'] = evals_result['validation_0']['auc']\n",
    "    gc.collect()\n",
    "    print(\"70 done\")\n",
    "    clf, evals_result = xgb_train(X_total[col_80])\n",
    "    pickle.dump(clf, open(f'model/{feature_name}_80_clf.pkl.gz', 'wb'))\n",
    "    plot_df['80'] = evals_result['validation_0']['auc']\n",
    "    gc.collect()\n",
    "    print(\"80 done\")\n",
    "    clf, evals_result = xgb_train(X_total[col_90])\n",
    "    pickle.dump(clf, open(f'model/{feature_name}_90_clf.pkl.gz', 'wb'))\n",
    "    plot_df['90'] = evals_result['validation_0']['auc']\n",
    "    gc.collect()\n",
    "    print(\"100 done\")\n",
    "    clf = pickle.load(open(modelname, 'rb'))\n",
    "    plot_df['100'] = clf.evals_result()['validation_0']['auc']\n",
    "    gc.collect()\n",
    "    \n",
    "    labels = ['70%', '80%', '90%', '100%']\n",
    "    plt.boxplot(plot_df.T, showfliers=False, labels=labels, vert=True)\n",
    "    plt.grid(True)\n",
    "    plt.xticks(rotation=20)\n",
    "    plt.ylabel('AUC')\n",
    "    plt.title(f'evaluation within {feature_name} groups')\n",
    "    plt.show()\n",
    "\u001f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_within_groups('confidence_rate_feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_within_groups('group_by_feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_within_groups('next_click_feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_within_groups('history_click_feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_within_groups('topic_feature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur_sum = 0\n",
    "for i, col in enumerate(importance_df.index):\n",
    "    cur_sum += weight_list[i]\n",
    "    if 1.0*cur_sum/sum_features < 0.9:   \n",
    "        col_90.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chosen_features = col_90\n",
    "feature_name = \"confidence_rate_feature\"\n",
    "feat_mat = f\"feature/{feature_name}.pkl.gz\"\n",
    "X_total_ = pd.read_pickle(feat_mat)\n",
    "X_chosen = X_total_[chosen_features]\n",
    "X_total = pd.concat([X_total,X_chosen],axis=1) \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chosen_features = col_90\n",
    "feature_name = \"group_by_feature\"\n",
    "feat_mat = f\"feature/{feature_name}.pkl.gz\"\n",
    "X_total_ = pd.read_pickle(feat_mat)\n",
    "X_chosen = X_total_[chosen_features]\n",
    "X_total = pd.concat([X_total,X_chosen],axis=1) \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chosen_features = col_90\n",
    "feature_name = \"next_click_feature\"\n",
    "feat_mat = f\"feature/{feature_name}.pkl.gz\"\n",
    "X_total_ = pd.read_pickle(feat_mat)\n",
    "X_chosen = X_total_[chosen_features]\n",
    "X_total = pd.concat([X_total,X_chosen],axis=1) \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chosen_features = col_90\n",
    "feature_name = \"history_click_feature\"\n",
    "feat_mat = f\"feature/{feature_name}.pkl.gz\"\n",
    "X_total_ = pd.read_pickle(feat_mat)\n",
    "X_chosen = X_total_[chosen_features]\n",
    "X_total = pd.concat([X_total,X_chosen],axis=1) \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chosen_features = col_90\n",
    "feature_name = \"topic_feature\"\n",
    "feat_mat = f\"feature/{feature_name}.pkl.gz\"\n",
    "X_total_ = pd.read_pickle(feat_mat)\n",
    "X_chosen = X_total_[chosen_features]\n",
    "X_total = pd.concat([X_total,X_chosen],axis=1) \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "separate train/dev/test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_total = pd.read_pickle('X_total_fea.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_total.drop(['click_time'], axis=1, inplace=True)\n",
    "X_total = X_total.fillna(0)\n",
    "X_train = X_total[X_total['day']!=9]\n",
    "X_test = X_total[X_total['day']==9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Negative down-sampling (posive : negative = 1 : 1)\n",
    "\n",
    "sample 3 different down-sampling dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_train = X_train[X_train['is_attributed']==1]\n",
    "neg_train = X_train[X_train['is_attributed']==0]\n",
    "n_pos_train = len(pos_train)\n",
    "\n",
    "sampled_data = {}\n",
    "\n",
    "for i in range(3):\n",
    "    sampled_data[i] = pd.concat([neg_train.sample(n=n_pos_train), pos_train]).reset_index(drop=True)\n",
    "del pos_train, neg_train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(sampled_data[0].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### experiment on the effect of down-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_df = pd.DataFrame()\n",
    "\n",
    "for i in range(6):\n",
    "    clf, evals_result = xgb_train(sampled_data[i])\n",
    "    plot_df[f'neg:pos={i+1}:1'] = evals_result['validation_0']['auc']\n",
    "    gc.collect()\n",
    "    modelname = f\"model/neg_pos_{i+1}_1_clf.pkl.gz\"\n",
    "    pickle.dump(clf, open(modelname, 'wb'))\n",
    "    print(f\"neg:pos={i+1}:1 done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = ['neg:pos=1:1','neg:pos=2:1','neg:pos=3:1','neg:pos=4:1','neg:pos=5:1']\n",
    "plt.boxplot(plot_df[['neg:pos=2:1','neg:pos=3:1','neg:pos=4:1','neg:pos=5:1','neg:pos=6:1']].T, showfliers=False, labels=labels, vert=True)\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylabel('AUC')\n",
    "plt.title(f'different proportions of negative down-sampling')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.Training XGBoost Model on 3 different sampled datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "for i in range(3):\n",
    "    X = sampled_data[i].drop(['is_attributed'], axis=1)\n",
    "    y = sampled_data[i]['is_attributed']\n",
    "    model = grid_search_cv(X, y)\n",
    "    filename = f'model/model_{i}.sav'\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='phase3'></a>\n",
    "## Phase 3 : Predict & Evaluate & Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Predict test set using well-trained model\n",
    "\n",
    "2.Generate submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sample = pd.read_csv('../input/sample_submission.csv')\n",
    "eval_result = pd.DataFrame()\n",
    "eval_result['label'] = X_test['is_attributed']\n",
    "for i in range(3):\n",
    "    filename = f'model/model_{i}.sav'\n",
    "    clf = pickle.load(open(filename, 'rb'))\n",
    "    eval_result[f'pred_prob_{i}'] = clf.predict_proba(X_test.drop(['is_attributed'], axis=1).fillna(0))[:,1]\n",
    "#     sample.is_attributed = test_probs\n",
    "#     sample.to_csv(f\"submission/xgboost-chenlu-{i}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluate the result and plot the PR curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ensemble = pd.read_csv('submission_esb_1x_3n.csv')\n",
    "ensemble_3nn = pd.read_csv('submission_esb_3n.csv')\n",
    "ensemble_1x_3nn = pd.read_csv('submission_esb_1x_3n_newauc.csv')\n",
    "ensemble_1x_1nn = pd.read_csv('submission_esb_1x_1n.csv')\n",
    "szh_label = pd.read_csv('y_true.csv')\n",
    "szh_pred1 = pd.read_csv('submission/y_pred1.csv')\n",
    "szh_pred2 = pd.read_csv('submission/y_pred2.csv')\n",
    "szh_pred3 = pd.read_csv('submission/y_pred3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=1, figsize=(8, 6))\n",
    "\n",
    "def add_line(label, predict, line_name):\n",
    "    y_label = label\n",
    "    y_prob = predict\n",
    "    \n",
    "    precision, recall, _ = precision_recall_curve(y_label, y_prob)\n",
    "    average_precision = average_precision_score(y_label, y_prob)\n",
    "    \n",
    "    plt.step(recall, precision, alpha=0.8, label=f'{line_name} pr_auc:{average_precision:0.6f}', where='post')\n",
    "    \n",
    "\n",
    "plt.sca(axs)\n",
    "add_line(eval_result['label'], eval_result['pred_prob_0'], \"xgb_1\")\n",
    "add_line(eval_result['label'], szh_pred1['0'], \"DNN_1\")\n",
    "add_line(eval_result['label'], szh_pred2['0'], \"DNN_2\")\n",
    "add_line(eval_result['label'], szh_pred3['0'], \"DNN_3\")\n",
    "add_line(eval_result['label'], ensemble_1x_3nn['is_attributed'],'ensemble_1x_3nn')\n",
    "add_line(eval_result['label'], ensemble_3nn['is_attributed'],'ensemble_3nn')\n",
    "add_line(eval_result['label'], ensemble_1x_1nn['is_attributed'],'ensemble_1x_1nn')\n",
    "\n",
    "\n",
    "# add_line(eval_result['label'], eval_result['pred_prob_3'], \"model_3\")\n",
    "\n",
    "plt.legend(loc=0, prop={'size': 12})\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "\n",
    "plt.title(f'PR Curve in test set')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:snorpy3]",
   "language": "python",
   "name": "conda-env-snorpy3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
